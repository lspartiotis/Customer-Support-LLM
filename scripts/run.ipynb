{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lspartiotis/Desktop/ShowcaseLLM/app/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           instruction category        intent  \\\n",
      "count                            26872    26872         26872   \n",
      "unique                           24635       11            27   \n",
      "top     shipments to {{Delivery City}}  ACCOUNT  edit_account   \n",
      "freq                                 8     5986          1000   \n",
      "\n",
      "                                                 response  \n",
      "count                                               26872  \n",
      "unique                                              26870  \n",
      "top     Firstly, I truly understand how pivotal the {{...  \n",
      "freq                                                    2  \n",
      "intent\n",
      "edit_account                1000\n",
      "switch_account              1000\n",
      "check_invoice               1000\n",
      "complaint                   1000\n",
      "contact_customer_service    1000\n",
      "delivery_period              999\n",
      "registration_problems        999\n",
      "check_payment_methods        999\n",
      "contact_human_agent          999\n",
      "payment_issue                999\n",
      "newsletter_subscription      999\n",
      "get_invoice                  999\n",
      "place_order                  998\n",
      "cancel_order                 998\n",
      "track_refund                 998\n",
      "change_order                 997\n",
      "get_refund                   997\n",
      "create_account               997\n",
      "check_refund_policy          997\n",
      "review                       997\n",
      "set_up_shipping_address      997\n",
      "delivery_options             995\n",
      "delete_account               995\n",
      "recover_password             995\n",
      "track_order                  995\n",
      "change_shipping_address      973\n",
      "check_cancellation_fee       950\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "ACCOUNT         5986\n",
      "ORDER           3988\n",
      "REFUND          2992\n",
      "INVOICE         1999\n",
      "CONTACT         1999\n",
      "PAYMENT         1998\n",
      "FEEDBACK        1997\n",
      "DELIVERY        1994\n",
      "SHIPPING        1970\n",
      "SUBSCRIPTION     999\n",
      "CANCEL           950\n",
      "Name: count, dtype: int64\n",
      "category\n",
      "ACCOUNT         5986\n",
      "ORDER           3988\n",
      "REFUND          2992\n",
      "INVOICE         1999\n",
      "CONTACT         1999\n",
      "PAYMENT         1998\n",
      "FEEDBACK        1997\n",
      "DELIVERY        1994\n",
      "SHIPPING        1970\n",
      "SUBSCRIPTION     999\n",
      "CANCEL           950\n",
      "Name: count, dtype: int64\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['flags', 'instruction', 'category', 'intent', 'response', 'cleaned_text_x', 'cleaned_text_y'],\n",
      "        num_rows: 26872\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lspartiotis/Desktop/ShowcaseLLM/app/Customer-Support-LLM/scripts/data.py:25: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_grouped = df.groupby(['intent', 'category']).apply(lambda x: x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   flags                                        instruction category  \\\n",
      "0      B   question about cancelling order {{Order Number}}    ORDER   \n",
      "1    BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
      "2   BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
      "3     BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
      "4  BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
      "\n",
      "         intent                                           response  \\\n",
      "0  cancel_order  I've understood you have a question regarding ...   \n",
      "1  cancel_order  I've been informed that you have a question ab...   \n",
      "2  cancel_order  I can sense that you're seeking assistance wit...   \n",
      "3  cancel_order  I understood that you need assistance with can...   \n",
      "4  cancel_order  I'm sensitive to the fact that you're facing f...   \n",
      "\n",
      "                                      cleaned_text_x  \\\n",
      "0       question about cancelling order order number   \n",
      "1  i have a question about cancelling oorder orde...   \n",
      "2        i need help cancelling puchase order number   \n",
      "3             i need to cancel purchase order number   \n",
      "4  i cannot afford this order cancel purchase ord...   \n",
      "\n",
      "                                      cleaned_text_y  \\\n",
      "0  ive understood you have a question regarding c...   \n",
      "1  ive been informed that you have a question abo...   \n",
      "2  i can sense that youre seeking assistance with...   \n",
      "3  i understood that you need assistance with can...   \n",
      "4  im sensitive to the fact that youre facing fin...   \n",
      "\n",
      "                                       dialogue_pair  \n",
      "0  \\nCustomer: question about cancelling order or...  \n",
      "1  \\nCustomer: i have a question about cancelling...  \n",
      "2  \\nCustomer: i need help cancelling puchase ord...  \n",
      "3  \\nCustomer: i need to cancel purchase order nu...  \n",
      "4  \\nCustomer: i cannot afford this order cancel ...  \n"
     ]
    }
   ],
   "source": [
    "%run data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flags': 'BQ', 'instruction': 'i dont know what to do to cancel order {{Order Number}}', 'category': 'ORDER', 'intent': 'cancel_order', 'response': \"I've taken note that you're unsure of the cancellation process for your order with the order number {{Order Number}}. Don't worry, I'm here to help you! To cancel your order, please follow these steps:\\n\\n1. Sign into Your Account: Access our platform by signing in to your {{Online Company Portal Info}}. \\n2. Find Your Order: Once logged in, navigate to your '{{Online Order Interaction}}' or '{{Online Order Interaction}}' tab to locate the order with the order number {{Order Number}}.\\n3. Initiate Cancellation: Click on the order and look for the option labeled '{{Online Order Interaction}}'. Select this option to initiate the cancellation process.\\n4. Confirm Cancellation: The system might prompt you to confirm the cancellation. If so, kindly provide the necessary information to proceed.\\n5. Review Cancellation Details: After confirming, you will receive a cancellation confirmation with the relevant details. Make sure to review it for your records.\\n\\nIf you encounter any difficulties or have further questions, please don't hesitate to contact our dedicated support team. You can reach them during {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat on our website at {{Website URL}}. We're committed to providing the best assistance to ensure your satisfaction.\", 'cleaned_text_x': 'i dont know what to do to cancel order order number', 'cleaned_text_y': 'ive taken note that youre unsure of the cancellation process for your order with the order number order number dont worry im here to help you to cancel your order please follow these steps\\n\\n1 sign into your account access our platform by signing in to your online company portal info \\n2 find your order once logged in navigate to your online order interaction or online order interaction tab to locate the order with the order number order number\\n3 initiate cancellation click on the order and look for the option labeled online order interaction select this option to initiate the cancellation process\\n4 confirm cancellation the system might prompt you to confirm the cancellation if so kindly provide the necessary information to proceed\\n5 review cancellation details after confirming you will receive a cancellation confirmation with the relevant details make sure to review it for your records\\n\\nif you encounter any difficulties or have further questions please dont hesitate to contact our dedicated support team you can reach them during customer support hours at customer support phone number or through the live chat on our website at website url were committed to providing the best assistance to ensure your satisfaction', 'dialogue_pair': '\\nCustomer: i dont know what to do to cancel order order number<|endoftext|>\\nAssistant: ive taken note that youre unsure of the cancellation process for your order with the order number order number dont worry im here to help you to cancel your order please follow these steps\\n\\n1 sign into your account access our platform by signing in to your online company portal info \\n2 find your order once logged in navigate to your online order interaction or online order interaction tab to locate the order with the order number order number\\n3 initiate cancellation click on the order and look for the option labeled online order interaction select this option to initiate the cancellation process\\n4 confirm cancellation the system might prompt you to confirm the cancellation if so kindly provide the necessary information to proceed\\n5 review cancellation details after confirming you will receive a cancellation confirmation with the relevant details make sure to review it for your records\\n\\nif you encounter any difficulties or have further questions please dont hesitate to contact our dedicated support team you can reach them during customer support hours at customer support phone number or through the live chat on our website at website url were committed to providing the best assistance to ensure your satisfaction'}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Customer: question about cancelling order order number\n",
      "Assistant: ive understood you have a question regarding canceling order order number and im here to provide you with the information you need please go ahead and ask your question and ill do my best to assist you\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 26872/26872 [00:00<00:00, 404839.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flags': Value(dtype='string', id=None), 'instruction': Value(dtype='string', id=None), 'category': Value(dtype='string', id=None), 'intent': Value(dtype='string', id=None), 'response': Value(dtype='string', id=None), 'cleaned_text_x': Value(dtype='string', id=None), 'cleaned_text_y': Value(dtype='string', id=None), 'dialogue_pair': Value(dtype='string', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n",
      "Dataset({\n",
      "    features: ['dialogue_pair', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 21497\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run tokenizer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "το Training λόγω συγκεκριμένων βιβλιοθηκών έχει θέμα με τον gpu accelerator του apple slicon mac \"MPS\" οπότε δεν μπορεί να τρέξει locally σε mac, σε windows PC δεν θα έχει πρόβλημα αρκεί η gpu να διαθέτει αρκετή μνήμη. (το τρέξαμε σε Α100 στο google colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is using device: mps\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/ShowcaseLLM/app/Customer-Support-LLM/scripts/model.py:56\u001b[0m\n\u001b[1;32m     53\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metric\u001b[38;5;241m.\u001b[39mcompute(predictions\u001b[38;5;241m=\u001b[39mpredictions, references\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m---> 56\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#this will be usd in the pipeline for inference\u001b[39;49;00m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Enable mixed precision training\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Save a checkpoint every 1000 steps\u001b[39;49;00m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Keep only the last 2 checkpoints\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#eval_strategy=\"epoch\",  # Use eval_strategy instead of evaluation_strategy\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m#eval_steps=10,\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m#do_eval=False,\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m#eval_accumulation_steps=1,\u001b[39;00m\n\u001b[1;32m     76\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     77\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     78\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39meval_dataset,\n\u001b[1;32m     82\u001b[0m )\n",
      "File \u001b[0;32m<string>:128\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics)\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/ShowcaseLLM/app/lib/python3.12/site-packages/transformers/training_args.py:1641\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1635\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version\u001b[38;5;241m.\u001b[39mparse(version\u001b[38;5;241m.\u001b[39mparse(torch\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mbase_version) \u001b[38;5;241m==\u001b[39m version\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16:\n\u001b[1;32m   1636\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1639\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1640\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m-> 1641\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_greater_or_equal_than_2_3)\n\u001b[1;32m   1642\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1644\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1645\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1646\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (get_xla_device_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp16_full_eval)\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1651\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (`--fp16_full_eval`) can only be used on CUDA or MLU devices or NPU devices or certain XPU devices (with IPEX).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1652\u001b[0m     )\n\u001b[1;32m   1654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_torch_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf16_full_eval)\n\u001b[1;32m   1665\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/ShowcaseLLM/app/lib/python3.12/site-packages/transformers/training_args.py:2149\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2145\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2146\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[1;32m   2147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2148\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 2149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ShowcaseLLM/app/lib/python3.12/site-packages/transformers/utils/generic.py:59\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     57\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[0;32m~/Desktop/ShowcaseLLM/app/lib/python3.12/site-packages/transformers/training_args.py:2055\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2054\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 2055\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   2056\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2057\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2058\u001b[0m         )\n\u001b[1;32m   2059\u001b[0m     AcceleratorState\u001b[38;5;241m.\u001b[39m_reset_state(reset_partial_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2060\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "%run model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
